Bias²: с ростом гибкости модели она может точнее аппроксимировать истинную функцию, поэтому bias уменьшается. Гибкие модели способны уловить сложные зависимости, что снижает систематическую ошибку.

Variance: чем более гибкая модель, тем сильнее она зависит от обучающей выборки. Малейшие изменения в данных могут сильно повлиять на структуру модели, поэтому variance растёт с гибкостью.

Training Error: при увеличении гибкости модель всё лучше подгоняется под обучающие данные, вплоть до переобучения. Поэтому training error монотонно убывает, потенциально до нуля.

Test Error: состоит из суммы bias² + variance + irreducible error. Имеет U-образную форму: при малой гибкости ошибка высокая из-за большого bias, при слишком большой — из-за высокого variance. Минимум достигается при оптимальном балансе между bias и variance. Интерпретация: сначала модель находит реальные закономерности, затем — начинает "обучаться шуму".

Irreducible Error: это шум в данных, который невозможно устранить никакой моделью. Эта ошибка постоянна и отображается на графике как горизонтальная линия.