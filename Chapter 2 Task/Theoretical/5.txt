What are the advantages and disadvantages of a very fexible (versus
a less fexible) approach for regression or classifcation? Under what
circumstances might a more fexible approach be preferred to a less
fexible approach? When might a less fexible approach be preferred?

В целом это задание относиться к 1. Давайте разберемся попярдку:
Более гибкая модель, которая может находить более сложные зависимости, однако  есть риск, что мы начнем слишком сильно подгонять нашу модель под тренировочкую выборку и получим переобучение. В регрессии это значит что наши ответы на тестовой выборке не будут  отражать  реальности, шумы которые были во время обучения пропали и модель не дает правильный числовой результат. Классификация же становится слишком чувствительной к параметрам, например, если мы возмем задачу определения кошка или собака на изображении из прошлого задания, мы можем начать воспринимать цвет шерсти или задний фон как важный параметр, а не "шум", однако слишком простая модель вовсе может не проследить нужные параметры и их зависимости.
n>>p - хороша гибка модель
n<<p - хороша не гибкая модель
n ~ p - по ситуации, но в целом что-то среднее
Var(\eps) - большая - хороша не гибка модель, тк у нас тут большой шум, которые может показаться как зависимость
Линейная зависимость между параметрами и выходом - хорошая не гибкая, тк гибкая начнет строить слишком сложные зависимости между входными данными и получит функцию которая будет слишком серьезно воспринимать шумы
